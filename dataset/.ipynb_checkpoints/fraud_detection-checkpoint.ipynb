{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e2a61e",
   "metadata": {},
   "source": [
    "# AI-Powered Fraud Detection System\n",
    "\n",
    "This notebook implements a machine learning model to detect fraudulent transactions with minimal false positives. The workflow includes data exploration, preprocessing, model training, evaluation, and simulated deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore the Dataset\n",
    "train_df = pd.read_csv('train_hsbc_df.csv')\n",
    "test_df = pd.read_csv('test_hsbc_df.csv')\n",
    "\n",
    "print('Train Data Shape:', train_df.shape)\n",
    "print('Test Data Shape:', test_df.shape)\n",
    "\n",
    "print('Train Data Sample:')\n",
    "display(train_df.head())\n",
    "\n",
    "print('Class Distribution:')\n",
    "if 'is_fraud' in train_df.columns:\n",
    "    sns.countplot(x='is_fraud', data=train_df)\n",
    "    plt.title('Fraudulent vs Non-Fraudulent Transactions')\n",
    "    plt.show()\n",
    "    print(train_df['is_fraud'].value_counts(normalize=True))\n",
    "else:\n",
    "    print('No fraud label found in train data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data (Cleaning & Feature Engineering)\n",
    "# Handle missing values\n",
    "train_df = train_df.fillna(train_df.median(numeric_only=True))\n",
    "test_df = test_df.fillna(train_df.median(numeric_only=True))\n",
    "\n",
    "# Encode categorical features\n",
    "cat_cols = train_df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "\n",
    "# Scale numerical features\n",
    "num_cols = train_df.select_dtypes(include=['float64', 'int64']).columns.drop('is_fraud', errors='ignore')\n",
    "scaler = StandardScaler()\n",
    "train_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b765273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Test Sets\n",
    "X = train_df.drop('is_fraud', axis=1)\n",
    "y = train_df['is_fraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print('Training set shape:', X_train.shape)\n",
    "print('Validation set shape:', X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Fraud Detection Model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('Model training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "val_preds = rf.predict(X_val)\n",
    "val_probs = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "precision = precision_score(y_val, val_preds)\n",
    "recall = recall_score(y_val, val_preds)\n",
    "f1 = f1_score(y_val, val_preds)\n",
    "auc = roc_auc_score(y_val, val_probs)\n",
    "cm = confusion_matrix(y_val, val_preds)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n",
    "print('AUC-ROC:', auc)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, val_probs)\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48300263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Model to Minimize False Positives\n",
    "# Adjust decision threshold\n",
    "threshold = 0.5  # Default\n",
    "custom_preds = (val_probs > threshold).astype(int)\n",
    "\n",
    "custom_precision = precision_score(y_val, custom_preds)\n",
    "custom_recall = recall_score(y_val, custom_preds)\n",
    "custom_f1 = f1_score(y_val, custom_preds)\n",
    "custom_cm = confusion_matrix(y_val, custom_preds)\n",
    "\n",
    "print(f'Custom Threshold: {threshold}')\n",
    "print('Precision:', custom_precision)\n",
    "print('Recall:', custom_recall)\n",
    "print('F1 Score:', custom_f1)\n",
    "print('Confusion Matrix:\\n', custom_cm)\n",
    "\n",
    "# You can tune threshold to minimize false positives by iterating over possible values and selecting the best trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23529d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Model for Deployment\n",
    "joblib.dump(rf, 'fraud_detection_model.joblib')\n",
    "print('Model saved as fraud_detection_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy Model (Simulated Prediction on New Data)\n",
    "loaded_model = joblib.load('fraud_detection_model.joblib')\n",
    "test_preds = loaded_model.predict(test_df)\n",
    "test_probs = loaded_model.predict_proba(test_df)[:, 1]\n",
    "\n",
    "# Export predictions to CSV\n",
    "output = pd.DataFrame({'transaction_id': test_df.index, 'is_fraud_pred': test_preds, 'fraud_probability': test_probs})\n",
    "output.to_csv('fraud_predictions.csv', index=False)\n",
    "print('Predictions saved to fraud_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5570a1",
   "metadata": {},
   "source": [
    "# Conclusion & Next Steps\n",
    "\n",
    "- The RandomForest model was trained to detect fraudulent transactions with a focus on minimizing false positives.\n",
    "- Key metrics (precision, recall, F1, AUC-ROC) were evaluated to ensure robust performance.\n",
    "- Feature importance can be visualized and analyzed to understand which features drive predictions.\n",
    "- The model and predictions are exported for deployment and further analysis.\n",
    "\n",
    "**Next Steps:**\n",
    "- Further tune model hyperparameters and thresholds for optimal trade-off.\n",
    "- Explore additional feature engineering and advanced models (e.g., XGBoost).\n",
    "- Integrate the model into a real-time transaction monitoring system."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
